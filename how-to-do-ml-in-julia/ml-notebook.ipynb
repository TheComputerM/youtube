{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Julia (using the Iris dataset)\n",
    "\n",
    "We will be creating a machine learning model using Julia and Flux.jl to classify types of flowers using the [Iris dataset](https://www.kaggle.com/uciml/iris#Iris.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.3.0\n",
      "Commit 46ce4d7933 (2019-11-26 06:09 UTC)\n",
      "Platform Info:\n",
      "  OS: Windows (x86_64-w64-mingw32)\n",
      "  CPU: Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo() # Information of the environment I am using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "We will be using [IJulia](https://github.com/JuliaLang/IJulia.jl) to run the Julia kernel inside this jupyter notebook.\n",
    "\n",
    "For this project we will be using Julia version 1.3.0 and some packages wich are listed below:\n",
    "- [CSV.jl](https://juliadata.github.io/CSV.jl/stable/)\n",
    "- [Flux.jl](https://fluxml.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add the denpendencies run:\n",
    "# Prefereabley run this in the terminal\n",
    "using Pkg\n",
    "Pkg.add(\"IJulia\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Dependencies\n",
    "using CSV, Flux\n",
    "# The first time you import them, it will take a lot of time for them to precompile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Array{CSV.Row{false},1}:\n",
       " [1, 5.1, 3.5, 1.4, 0.2, \"Iris-setosa\"]     \n",
       " [2, 4.9, 3.0, 1.4, 0.2, \"Iris-setosa\"]     \n",
       " [3, 4.7, 3.2, 1.3, 0.2, \"Iris-setosa\"]     \n",
       " [4, 4.6, 3.1, 1.5, 0.2, \"Iris-setosa\"]     \n",
       " [5, 5.0, 3.6, 1.4, 0.2, \"Iris-setosa\"]     \n",
       " [6, 5.4, 3.9, 1.7, 0.4, \"Iris-setosa\"]     \n",
       " [7, 4.6, 3.4, 1.4, 0.3, \"Iris-setosa\"]     \n",
       " [8, 5.0, 3.4, 1.5, 0.2, \"Iris-setosa\"]     \n",
       " [9, 4.4, 2.9, 1.4, 0.2, \"Iris-setosa\"]     \n",
       " [10, 4.9, 3.1, 1.5, 0.1, \"Iris-setosa\"]    \n",
       " [11, 5.4, 3.7, 1.5, 0.2, \"Iris-setosa\"]    \n",
       " [12, 4.8, 3.4, 1.6, 0.2, \"Iris-setosa\"]    \n",
       " [13, 4.8, 3.0, 1.4, 0.1, \"Iris-setosa\"]    \n",
       " ⋮                                          \n",
       " [139, 6.0, 3.0, 4.8, 1.8, \"Iris-virginica\"]\n",
       " [140, 6.9, 3.1, 5.4, 2.1, \"Iris-virginica\"]\n",
       " [141, 6.7, 3.1, 5.6, 2.4, \"Iris-virginica\"]\n",
       " [142, 6.9, 3.1, 5.1, 2.3, \"Iris-virginica\"]\n",
       " [143, 5.8, 2.7, 5.1, 1.9, \"Iris-virginica\"]\n",
       " [144, 6.8, 3.2, 5.9, 2.3, \"Iris-virginica\"]\n",
       " [145, 6.7, 3.3, 5.7, 2.5, \"Iris-virginica\"]\n",
       " [146, 6.7, 3.0, 5.2, 2.3, \"Iris-virginica\"]\n",
       " [147, 6.3, 2.5, 5.0, 1.9, \"Iris-virginica\"]\n",
       " [148, 6.5, 3.0, 5.2, 2.0, \"Iris-virginica\"]\n",
       " [149, 6.2, 3.4, 5.4, 2.3, \"Iris-virginica\"]\n",
       " [150, 5.9, 3.0, 5.1, 1.8, \"Iris-virginica\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = convert(Array, CSV.File(\"./Iris.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are 150 elements in the dataset. We will now remove about 20 random elements to be used as testing data.\n",
    "This is the layout of the dataset:\n",
    "\n",
    "|ID|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|Species|\n",
    "|---|---|---|---|---|---|\n",
    "|1|5.1|3.5|1.4|0.2|\"Iris-setosa\"|\n",
    "|2|4.9|3.0|1.4|0.2|\"Iris-setosa\"|\n",
    "|...|...|...|...|...|...|\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = []\n",
    "traindata = dataset\n",
    "for _ in 1:20\n",
    "    randindex = rand(1:length(dataset))\n",
    "    push!(testdata, dataset[randindex])\n",
    "    splice!(traindata, randindex)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Flux.OneHotVector} with 3 entries:\n",
       "  \"Iris-virginica\"  => Bool[1, 0, 0]\n",
       "  \"Iris-setosa\"     => Bool[0, 0, 1]\n",
       "  \"Iris-versicolor\" => Bool[0, 1, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us create a dictionary for julia to associate numbers with types of flowers\n",
    "labelDict = Dict(\"Iris-setosa\" => Flux.onehot(3, 1:3), \n",
    "    \"Iris-versicolor\" => Flux.onehot(2, 1:3), \n",
    "    \"Iris-virginica\" => Flux.onehot(1, 1:3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "First we are going to create a function to create batches that will return `Flux.batch` which are just arrays that are optimised to be trained with Flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_batch(data)\n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for i in 1:length(data)\n",
    "        SepalLengthCm = data[i][2]\n",
    "        SepalWidthCm = data[i][3]\n",
    "        PetalLengthCm = data[i][4]\n",
    "        PetalWidthCm = data[i][5]\n",
    "    \n",
    "        label = labelDict[data[i][6]]\n",
    "        \n",
    "        push!(inputData, [SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm])\n",
    "        push!(labels, label)\n",
    "    end\n",
    "    return (Flux.batch(inputData), Flux.batch(labels))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Flux.onehot` creates a onehote vector with one true value and the other values as false, we can use it to label our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Flux.OneHotVector:\n",
       " 0\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.onehot(2, 1:3) # Second element as true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], Bool[0 0 … 1 1; 0 0 … 0 0; 1 1 … 0 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbatch = create_batch(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most important and easy part\n",
    "We are now going to create our neural network. `Dense` means a single dense neuron with 4 inputs (SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm) and 3 outputs ([0, 0, 1] etc to denote out probability outputs).\n",
    "\n",
    "We are going to use the `sigma` σ function to classify our decision boundries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.134458 seconds (82.32 k allocations: 3.905 MiB)\n"
     ]
    }
   ],
   "source": [
    "model = Dense(4, 3, σ)\n",
    "L(x, y) = Flux.mse(model(x), y) # This is the loss function to test how our model is doing\n",
    "ps = Flux.params(model)\n",
    "opt = Descent() # This is the optimiser we will be using\n",
    "@time Flux.train!(L, ps, [trainbatch], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(L, ps, Iterators.repeated(trainbatch, 1000), opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the loss value after training the dataset to see how it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07934447f0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(trainbatch...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.3 6.9 … 5.3 5.1; 2.5 3.1 … 3.7 3.8; 5.0 5.4 … 1.5 1.5; 1.9 2.1 … 0.2 0.3], Bool[1 1 … 0 0; 0 0 … 0 0; 0 0 … 1 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbatch = create_batch(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06459588f0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(testbatch...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
